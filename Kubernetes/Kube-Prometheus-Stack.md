# ğŸš€ **Kube-Prometheus-Stack Deployment**
For internal domain: **apsis.localnet**

---

## ğŸ§© **0) Prerequisites**
- âœ… Kubernetes cluster (v1.21+)
- âœ… `kubectl` and `helm` installed
- âœ… Ingress Controller (NGINX or equivalent)
- âœ… DNS for:
  - `grafanax.apsis.localnet`
  - `prometheusx.apsis.localnet`
  - `alertmanagerx.apsis.localnet`
  â†’ All pointing to **192.168.20.162**

---

## âš™ï¸ **1) Create Namespace**
```bash
kubectl create namespace monitoring
```

---

## ğŸ§¾ **2) Prepare `values.yaml`**
Create file at `~/kube-prometheus-stack/values.yaml`:

```yaml
# --- Grafana ---
grafana:
  adminUser: admin
  adminPassword: "ChangeMeNow!"   # set a strong internal password
  service:
    type: ClusterIP
  ingress:
    enabled: true
    ingressClassName: nginx       # or your class name
    hosts:
      - grafanax.apsis.localnet
    path: /
    pathType: Prefix
    tls: []                       # add TLS block if you have internal CA/secret

# --- Prometheus ---
prometheus:
  service:
    type: ClusterIP
  ingress:
    enabled: true
    ingressClassName: nginx
    hosts:
      - prometheusx.apsis.localnet
    path: /
    pathType: Prefix
    tls: []
  prometheusSpec:
    retention: 15d
    scrapeInterval: 30s

# --- Alertmanager ---
alertmanager:
  service:
    type: ClusterIP
  ingress:
    enabled: true
    ingressClassName: nginx
    hosts:
      - alertmanagerx.apsis.localnet
    path: /
    pathType: Prefix
    tls: []

# Reduce noise: only if you want fewer example rules/targets
defaultRules:
  create: true

# Optional: Persistent storage (uncomment & tailor)
# prometheus:
#   prometheusSpec:
#     storageSpec:
#       volumeClaimTemplate:
#         spec:
#           accessModes: ["ReadWriteOnce"]
#           resources:
#             requests:
#               storage: 50Gi
# grafana:
#   persistence:
#     enabled: true
#     size: 10Gi
# alertmanager:
#   alertmanagerSpec:
#     storage:
#       volumeClaimTemplate:
#         spec:
#           accessModes: ["ReadWriteOnce"]
#           resources:
#             requests:
#               storage: 10Gi
```

---

## ğŸš€ **3) Install Chart**
```bash
helm upgrade kube-prometheus-stack \
  oci://ghcr.io/prometheus-community/charts/kube-prometheus-stack \
  --version 79.4.0 \
  -n monitoring \
  -f values.yaml
```

Or using Helm repo:
```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
  -n monitoring -f values.yaml
```

---

## ğŸ” **4) Verify**
```bash
kubectl get pods -n monitoring
kubectl get svc -n monitoring
kubectl get ingress -n monitoring
```

Access via browser:
- ğŸŒ Grafana â†’ http://grafanax.apsis.localnet  
- ğŸ“Š Prometheus â†’ http://prometheusx.apsis.localnet  
- ğŸš¨ Alertmanager â†’ http://alertmanagerx.apsis.localnet

---

# ğŸ”„ **Apply Configuration Changes (values.yaml Updates)**

## âœï¸ **1) Edit the values file**
```bash
nano ~/kube-prometheus-stack/values.yaml
```

## âš¡ **2) Apply updated configuration**
If deployed via OCI:
```bash
helm upgrade kube-prometheus-stack \
  oci://ghcr.io/prometheus-community/charts/kube-prometheus-stack \
  -n monitoring -f values.yaml
```
Or if using the Helm repo:
```bash
helm upgrade kube-prometheus-stack prometheus-community/kube-prometheus-stack \
  -n monitoring -f values.yaml
```

## ğŸ” **3) Verify rollout**
```bash
kubectl get pods -n monitoring
kubectl get ingress -n monitoring
helm status kube-prometheus-stack -n monitoring
```

## ğŸ§  **4) Dry-run test (preview without applying)**
```bash
helm upgrade kube-prometheus-stack prometheus-community/kube-prometheus-stack \
  -n monitoring -f values.yaml --dry-run --debug
```

## âª **5) Rollback if needed**
List revisions:
```bash
helm history kube-prometheus-stack -n monitoring
```
Rollback to a previous version:
```bash
helm rollback kube-prometheus-stack <REVISION_NUMBER> -n monitoring
```

---

# ğŸ§¼ **Uninstallation / Cleanup Steps**

## ğŸ—‘ï¸ **A) Uninstall Helm Release**
```bash
helm uninstall kube-prometheus-stack -n monitoring
```

## ğŸ“¦ **B) Remove PVCs**
```bash
kubectl get pvc -n monitoring
kubectl delete pvc -n monitoring -l app.kubernetes.io/instance=kube-prometheus-stack
```

## ğŸ§± **C) Remove CRDs**
```bash
kubectl get crds | grep monitoring.coreos.com
kubectl delete crd alertmanagers.monitoring.coreos.com \
  alertmanagerconfigs.monitoring.coreos.com \
  podmonitors.monitoring.coreos.com \
  probes.monitoring.coreos.com \
  prometheuses.monitoring.coreos.com \
  prometheusrules.monitoring.coreos.com \
  servicemonitors.monitoring.coreos.com \
  thanosrulers.monitoring.coreos.com
```

## âš™ï¸ **D) Remove Leftovers**
```bash
kubectl delete ingress -n monitoring --all
kubectl delete secret -n monitoring --all
```

## ğŸ§¾ **E) Delete Namespace**
```bash
kubectl delete namespace monitoring
```

---

âœ… **SOP Verified**  
This process deploys and manages the full Kube-Prometheus-Stack accessible at:
- Grafana â†’ `grafanax.apsis.localnet`
- Prometheus â†’ `prometheusx.apsis.localnet`
- Alertmanager â†’ `alertmanagerx.apsis.localnet`
